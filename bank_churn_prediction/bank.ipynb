{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-preparation\" data-toc-modified-id=\"Data-preparation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data preparation</a></span></li><li><span><a href=\"#Problem-exploration\" data-toc-modified-id=\"Problem-exploration-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Problem exploration</a></span></li><li><span><a href=\"#Fighting-imbalance\" data-toc-modified-id=\"Fighting-imbalance-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Fighting imbalance</a></span></li><li><span><a href=\"#Model-testing\" data-toc-modified-id=\"Model-testing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model testing</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Clients began to leave Beta Bank. Every month. A little, but noticeable. Bank marketers have calculated that it is cheaper to retain current customers than to attract new ones.\n",
    "\n",
    "It is necessary to predict whether the client will leave the bank in the near future or not. You are provided with historical data on customer behavior and termination of contracts with the bank.\n",
    "\n",
    "Build a model with a large value of the *F1*-measure. To pass the project successfully, you need to bring the metric to 0.59. Check the *F1*-measure on the test sample yourself.\n",
    "\n",
    "Additionally, measure *AUC-ROC*, compare its value with the *F1*-measure.\n",
    "\n",
    "Data source: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           9091 non-null   float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          0\n",
       "Geography            0\n",
       "Gender               0\n",
       "Age                  0\n",
       "Tenure             909\n",
       "Balance              0\n",
       "NumOfProducts        0\n",
       "HasCrCard            0\n",
       "IsActiveMember       0\n",
       "EstimatedSalary      0\n",
       "Exited               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Tenure'].fillna(df['Tenure'].median(), inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['creditscore', 'geography', 'gender', 'age', 'tenure', 'balance',\n",
       "       'num_of_products', 'has_credit_card', 'is_active_member',\n",
       "       'estimated_salary', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.rename(columns={'numofproducts': 'num_of_products',\n",
    "                   'hascrcard': 'has_credit_card',\n",
    "                   'isactivemember': 'is_active_member',\n",
    "                   'estimatedsalary': 'estimated_salary'}, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>creditscore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>350.00</td>\n",
       "      <td>584.00</td>\n",
       "      <td>652.000</td>\n",
       "      <td>718.0000</td>\n",
       "      <td>850.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>37.000</td>\n",
       "      <td>44.0000</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tenure</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>4.997900</td>\n",
       "      <td>2.760010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97198.540</td>\n",
       "      <td>127644.2400</td>\n",
       "      <td>250898.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_of_products</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_credit_card</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.705500</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_active_member</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estimated_salary</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.11</td>\n",
       "      <td>100193.915</td>\n",
       "      <td>149388.2475</td>\n",
       "      <td>199992.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exited</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean           std     min       25%  \\\n",
       "creditscore       10000.0     650.528800     96.653299  350.00    584.00   \n",
       "age               10000.0      38.921800     10.487806   18.00     32.00   \n",
       "tenure            10000.0       4.997900      2.760010    0.00      3.00   \n",
       "balance           10000.0   76485.889288  62397.405202    0.00      0.00   \n",
       "num_of_products   10000.0       1.530200      0.581654    1.00      1.00   \n",
       "has_credit_card   10000.0       0.705500      0.455840    0.00      0.00   \n",
       "is_active_member  10000.0       0.515100      0.499797    0.00      0.00   \n",
       "estimated_salary  10000.0  100090.239881  57510.492818   11.58  51002.11   \n",
       "exited            10000.0       0.203700      0.402769    0.00      0.00   \n",
       "\n",
       "                         50%          75%        max  \n",
       "creditscore          652.000     718.0000     850.00  \n",
       "age                   37.000      44.0000      92.00  \n",
       "tenure                 5.000       7.0000      10.00  \n",
       "balance            97198.540  127644.2400  250898.09  \n",
       "num_of_products        1.000       2.0000       4.00  \n",
       "has_credit_card        1.000       1.0000       1.00  \n",
       "is_active_member       1.000       1.0000       1.00  \n",
       "estimated_salary  100193.915  149388.2475  199992.48  \n",
       "exited                 0.000       0.0000       1.00  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The data was checked for missing values, data types, duplicates, and unnecessary columns. Data with user ids and last names should not affect the classification model, so they were removed. The index column is already there, which means \"RowNumber\" is not needed. Gaps in the column with the duration of cooperation with the bank (in years) \"Tenure\" have been replaced with 0. It should also be noted that the balance and estimated_salary columns have a large range and can greatly affect the model, so in the future we will use scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Problem exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['exited'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Classes are unbalanced, 20% of clients have left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_credit_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore  age  tenure    balance  num_of_products  has_credit_card  \\\n",
       "0          619   42     2.0       0.00                1                1   \n",
       "1          608   41     1.0   83807.86                1                0   \n",
       "2          502   42     8.0  159660.80                3                1   \n",
       "3          699   39     1.0       0.00                2                0   \n",
       "4          850   43     2.0  125510.82                1                1   \n",
       "\n",
       "   is_active_member  estimated_salary  exited  geography_Germany  \\\n",
       "0                 1         101348.88       1                  0   \n",
       "1                 1         112542.58       0                  0   \n",
       "2                 0         113931.57       1                  0   \n",
       "3                 0          93826.63       0                  0   \n",
       "4                 1          79084.10       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = df_ohe.drop(columns=['exited'])\n",
    "target = df_ohe['exited']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "features_valid, target_valid, test_size=0.5, random_state=12345)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[['balance', 'estimated_salary']])\n",
    "features_train[['balance', 'estimated_salary']] = scaler.transform(features_train[['balance', 'estimated_salary']])\n",
    "features_valid[['balance', 'estimated_salary']] = scaler.transform(features_valid[['balance', 'estimated_salary']])\n",
    "features_test[['balance', 'estimated_salary']] = scaler.transform(features_test[['balance', 'estimated_salary']])\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.3316412859560068\n",
      "auc_roc_score: 0.758238617460788\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=12345, solver='liblinear', max_iter=1000)\n",
    "logreg.fit(features_train, target_train)\n",
    "predicted_valid = logreg.predict(features_valid)\n",
    "predicted_prob = logreg.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_score = f1_score(target_valid, predicted_valid)\n",
    "auc_roc_score = roc_auc_score(target_valid, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.2792321116928447\n",
      "auc_roc_score: 0.7381103360811667\n"
     ]
    }
   ],
   "source": [
    "predicted_test = logreg.predict(features_test)\n",
    "predicted_prob = logreg.predict_proba(features_test)[:, 1]\n",
    "\n",
    "f1_score = metrics.f1_score(target_test, predicted_test)\n",
    "auc_roc_score = roc_auc_score(target_test, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_credit_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5639.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5793.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4704.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3925.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore  geography  gender   age  tenure  balance  num_of_products  \\\n",
       "0        228.0        0.0     0.0  24.0     2.0      0.0              0.0   \n",
       "1        217.0        2.0     0.0  23.0     1.0    743.0              0.0   \n",
       "2        111.0        0.0     0.0  24.0     8.0   5793.0              2.0   \n",
       "3        308.0        0.0     0.0  21.0     1.0      0.0              1.0   \n",
       "4        459.0        2.0     0.0  25.0     2.0   3696.0              0.0   \n",
       "\n",
       "   has_credit_card  is_active_member  estimated_salary  exited  \n",
       "0              1.0               1.0            5068.0     1.0  \n",
       "1              0.0               1.0            5639.0     0.0  \n",
       "2              1.0               0.0            5707.0     1.0  \n",
       "3              0.0               0.0            4704.0     0.0  \n",
       "4              1.0               1.0            3925.0     0.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(df)\n",
    "df_ord = encoder.transform(df)\n",
    "df_ord = pd.DataFrame(df_ord, columns=df.columns)\n",
    "df_ord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.5222929936305732\n",
      "auc_roc_score: 0.8539259470642792\n"
     ]
    }
   ],
   "source": [
    "features = df_ord.drop(columns=['exited'])\n",
    "target = df_ord['exited']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "forest = None\n",
    "max_depth = 0\n",
    "n_est = 0\n",
    "f1_best = 0\n",
    "for est in range(10, 81, 10):\n",
    "    for depth in range(3, 7):\n",
    "        forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        forest.fit(features_train, target_train)\n",
    "        predicted_valid = forest.predict(features_valid)\n",
    "        result = metrics.f1_score(target_valid, predicted_valid)\n",
    "    \n",
    "        if result > f1_best:\n",
    "            f1_best = result\n",
    "            n_est = est\n",
    "            max_depth = depth\n",
    "            forest_best = forest\n",
    "\n",
    "f1_score = metrics.f1_score(target_valid, predicted_valid)\n",
    "predicted_prob = forest.predict_proba(features_valid)[:, 1]\n",
    "auc_roc_score = roc_auc_score(target_valid, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 6 | number of estimators 60\n"
     ]
    }
   ],
   "source": [
    "print('max_depth', max_depth, '| number of estimators', n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Without taking into account class imbalance, the logistic regression model scores poorly, but the random forest has an f1 score of 0.52. We will use the model in further research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Fighting imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.800667\n",
       "1.0    0.199333\n",
       "Name: exited, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "features_zeros = features_train[target_train==0]\n",
    "features_ones = features_train[target_train==1]\n",
    "target_zeros = target_train[target_train==0]\n",
    "target_ones = target_train[target_train==1]\n",
    "\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones]*4)\n",
    "target_upsampled = pd.concat([target_zeros] + [target_ones]*4)\n",
    "features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.6208333333333333\n",
      "auc_roc_score: 0.8503574906695539\n"
     ]
    }
   ],
   "source": [
    "f1_score = 0\n",
    "n_estimators = 0\n",
    "max_depth = 0\n",
    "best_forest = None\n",
    "for est in range(10, 91, 10):\n",
    "    for depth in range(3, 10):\n",
    "        forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        forest.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = forest.predict(features_valid)\n",
    "        result = metrics.f1_score(target_valid, predicted_valid)\n",
    "        if result > f1_score:\n",
    "            f1_score = result\n",
    "            n_estimators = est\n",
    "            max_depth = depth\n",
    "            best_forest = forest\n",
    "        \n",
    "predicted_prob = forest.predict_proba(features_valid)[:, 1]\n",
    "auc_roc_score = roc_auc_score(target_valid, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 8 | number of estimators 60\n"
     ]
    }
   ],
   "source": [
    "print('max_depth', max_depth, '| number of estimators', n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.6223132036847493\n",
      "auc_roc_score: 0.8497556239754657\n"
     ]
    }
   ],
   "source": [
    "f1_score = 0\n",
    "n_estimators = 0\n",
    "max_depth = 0\n",
    "best_forest = None\n",
    "for est in range(10, 91, 10):\n",
    "    for depth in range(3, 10):\n",
    "        forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight='balanced')\n",
    "        forest.fit(features_train, target_train)\n",
    "        predicted_valid = forest.predict(features_valid)\n",
    "        result = metrics.f1_score(target_valid, predicted_valid)\n",
    "        if result > f1_score:\n",
    "            f1_score = result\n",
    "            n_estimators = est\n",
    "            max_depth = depth\n",
    "            best_forest = forest\n",
    "        \n",
    "predicted_prob = forest.predict_proba(features_valid)[:, 1]\n",
    "auc_roc_score = roc_auc_score(target_valid, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 6 | number of estimators 20\n"
     ]
    }
   ],
   "source": [
    "print('max_depth', max_depth, '| number of estimators', n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ohe.drop(columns=['exited'])\n",
    "target = df_ohe['exited']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "features_valid, target_valid, test_size=0.5, random_state=12345)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[['balance', 'estimated_salary']])\n",
    "features_train[['balance', 'estimated_salary']] = scaler.transform(features_train[['balance', 'estimated_salary']])\n",
    "features_valid[['balance', 'estimated_salary']] = scaler.transform(features_valid[['balance', 'estimated_salary']])\n",
    "features_test[['balance', 'estimated_salary']] = scaler.transform(features_test[['balance', 'estimated_salary']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_zeros = features_train[target_train==0]\n",
    "features_ones = features_train[target_train==1]\n",
    "target_zeros = target_train[target_train==0]\n",
    "target_ones = target_train[target_train==1]\n",
    "\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones]*4)\n",
    "target_upsampled = pd.concat([target_zeros] + [target_ones]*4)\n",
    "features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.4892703862660944\n",
      "auc_roc_score: 0.7633393620817933\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=12345, solver='liblinear', max_iter=1000)\n",
    "logreg.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = logreg.predict(features_valid)\n",
    "predicted_prob = logreg.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_score = metrics.f1_score(target_valid, predicted_valid)\n",
    "auc_roc_score = roc_auc_score(target_valid, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.488013698630137\n",
      "auc_roc_score: 0.7632365305863209\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=12345, solver='liblinear', max_iter=1000, class_weight='balanced')\n",
    "logreg.fit(features_train, target_train)\n",
    "predicted_valid = logreg.predict(features_valid)\n",
    "predicted_prob = logreg.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "f1_score = metrics.f1_score(target_valid, predicted_valid)\n",
    "auc_roc_score = roc_auc_score(target_valid, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Several methods were used to combat imbalance: scaling, upsampling, and adding the class_weight='balanced' parameter. The model performed better than the previous one, its f1 score is 0.62 on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ord.drop(columns=['exited'])\n",
    "target = df_ord['exited']\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "features_valid, target_valid, test_size=0.5, random_state=12345)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[['balance', 'estimated_salary']])\n",
    "features_train[['balance', 'estimated_salary']] = scaler.transform(features_train[['balance', 'estimated_salary']])\n",
    "features_valid[['balance', 'estimated_salary']] = scaler.transform(features_valid[['balance', 'estimated_salary']])\n",
    "features_test[['balance', 'estimated_salary']] = scaler.transform(features_test[['balance', 'estimated_salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.601015228426396\n",
      "auc_roc_score: 0.8522953328806078\n"
     ]
    }
   ],
   "source": [
    "predicted_test = best_forest.predict(features_test)\n",
    "predicted_prob = best_forest.predict_proba(features_test)[:, 1]\n",
    "\n",
    "f1_score = metrics.f1_score(target_test, predicted_test)\n",
    "auc_roc_score = roc_auc_score(target_test, predicted_prob)\n",
    "\n",
    "print('f1_score:', f1_score)\n",
    "print('auc_roc_score:', auc_roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The model performed well on the test sample as well. Judging by the roc_auc_score metric, the model will perform 0.85-0.5=0.35=35% better than a random model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**Final conclusion**:\n",
    "\n",
    "Data was provided about the bank's clients and their characteristics, such as client activity, account balance, availability of a credit card, etc. Many bank clients stop cooperating. Therefore, our task was to teach the model to identify loyal and leaving customers. Random forest and logistic regression models were trained with balanced and unbalanced classes and various hyperparameters. As a result, the best model turned out to be a random forest with parameters n_estimators=20, max_depth=6, class_weight='balanced'. The test sample score is 60%"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 54,
    "start_time": "2023-03-16T23:06:44.747Z"
   },
   {
    "duration": 549,
    "start_time": "2023-03-16T23:06:48.222Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-16T23:06:53.923Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-16T23:10:32.240Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-16T23:12:39.718Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-16T23:12:52.693Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-16T23:12:56.686Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-16T23:12:59.132Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-16T23:13:13.781Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-16T23:13:13.824Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-16T23:13:16.119Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-16T23:13:18.640Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-16T23:17:32.235Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-16T23:17:32.276Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-16T23:17:35.059Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-16T23:17:36.930Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-16T23:18:04.156Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-16T23:18:04.198Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-16T23:18:04.214Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-16T23:18:06.190Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-16T23:18:55.324Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-16T23:19:32.149Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-16T23:20:32.792Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-16T23:21:19.917Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-16T23:22:10.320Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-16T23:22:15.926Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-16T23:23:13.354Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-16T23:24:17.661Z"
   },
   {
    "duration": 76,
    "start_time": "2023-03-16T23:26:34.834Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-16T23:26:49.810Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-16T23:27:50.419Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-16T23:29:04.579Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-16T23:29:04.620Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-16T23:29:04.635Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-16T23:29:04.647Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-16T23:29:04.668Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-16T23:29:04.690Z"
   },
   {
    "duration": 80,
    "start_time": "2023-03-16T23:29:06.599Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-16T23:30:14.348Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-16T23:31:44.577Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-16T23:31:58.089Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-16T23:32:19.413Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-16T23:32:46.541Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-16T23:32:51.730Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-16T23:33:28.479Z"
   },
   {
    "duration": 758,
    "start_time": "2023-03-16T23:58:21.221Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-16T23:59:30.106Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-16T23:59:33.138Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-17T00:03:23.810Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T00:03:30.576Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T00:04:47.490Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T00:05:00.802Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-17T00:06:08.786Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-17T00:17:05.490Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T00:17:12.479Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T00:17:29.699Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-17T00:17:51.689Z"
   },
   {
    "duration": 137,
    "start_time": "2023-03-17T00:17:58.142Z"
   },
   {
    "duration": 136,
    "start_time": "2023-03-17T00:18:43.142Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T01:07:45.637Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:07:53.466Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-17T01:08:29.507Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-17T01:12:51.238Z"
   },
   {
    "duration": 30,
    "start_time": "2023-03-17T01:13:11.573Z"
   },
   {
    "duration": 38,
    "start_time": "2023-03-17T01:13:21.158Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T01:13:43.564Z"
   },
   {
    "duration": 388,
    "start_time": "2023-03-17T01:13:59.879Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:16:12.760Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T01:16:32.739Z"
   },
   {
    "duration": 448,
    "start_time": "2023-03-17T01:16:42.357Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-17T01:16:48.731Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-17T01:16:48.772Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T01:16:48.786Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-17T01:16:48.793Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-17T01:16:48.808Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-17T01:16:48.816Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T01:16:48.848Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T01:16:48.855Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-17T01:16:48.880Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:16:48.916Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-17T01:16:48.921Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T01:16:48.931Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T01:16:48.937Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-17T01:16:48.944Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-17T01:16:48.977Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-17T01:16:49.005Z"
   },
   {
    "duration": 123,
    "start_time": "2023-03-17T01:16:49.086Z"
   },
   {
    "duration": 436,
    "start_time": "2023-03-17T01:16:49.211Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-17T01:17:49.794Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T01:17:49.836Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-17T01:17:49.850Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-17T01:17:49.862Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-17T01:17:49.878Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-17T01:17:49.897Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T01:17:49.914Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-17T01:17:49.921Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-17T01:17:49.940Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T01:17:49.987Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-17T01:17:49.993Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-17T01:17:50.009Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-17T01:17:50.020Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-17T01:17:50.030Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-17T01:17:50.047Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-17T01:17:50.080Z"
   },
   {
    "duration": 129,
    "start_time": "2023-03-17T01:17:50.181Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T01:18:00.482Z"
   },
   {
    "duration": 447,
    "start_time": "2023-03-17T01:18:22.434Z"
   },
   {
    "duration": 426,
    "start_time": "2023-03-17T01:19:21.662Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-17T01:19:32.382Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-17T01:19:32.427Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-17T01:19:32.444Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-17T01:19:32.455Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-17T01:19:32.479Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-17T01:19:32.491Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T01:19:32.511Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-17T01:19:32.518Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-17T01:19:32.535Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:19:32.586Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-17T01:19:32.591Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T01:19:32.607Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T01:19:32.622Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-17T01:19:32.637Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-17T01:19:32.652Z"
   },
   {
    "duration": 90,
    "start_time": "2023-03-17T01:19:32.689Z"
   },
   {
    "duration": 126,
    "start_time": "2023-03-17T01:19:32.783Z"
   },
   {
    "duration": 422,
    "start_time": "2023-03-17T01:19:35.292Z"
   },
   {
    "duration": 383,
    "start_time": "2023-03-17T01:20:17.627Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T01:20:36.071Z"
   },
   {
    "duration": 407,
    "start_time": "2023-03-17T01:20:38.358Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T01:22:34.840Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T01:23:46.655Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-17T01:24:49.709Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-17T01:25:23.452Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T01:25:23.494Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-17T01:25:23.509Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-17T01:25:23.522Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-17T01:25:23.538Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-17T01:25:23.548Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T01:25:23.587Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-17T01:25:23.595Z"
   },
   {
    "duration": 36,
    "start_time": "2023-03-17T01:25:23.612Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:25:23.651Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-17T01:25:23.657Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-17T01:25:23.680Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-17T01:25:23.692Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-17T01:25:23.701Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-17T01:25:23.712Z"
   },
   {
    "duration": 140,
    "start_time": "2023-03-17T01:25:23.738Z"
   },
   {
    "duration": 125,
    "start_time": "2023-03-17T01:25:23.880Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-17T01:25:24.007Z"
   },
   {
    "duration": 424,
    "start_time": "2023-03-17T01:25:24.011Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-17T01:25:24.436Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-17T01:26:36.105Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-17T01:32:05.831Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-17T01:32:19.811Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T01:32:39.723Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-17T01:38:47.851Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T01:49:49.884Z"
   },
   {
    "duration": 19965,
    "start_time": "2023-03-17T01:50:09.763Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:51:26.142Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:51:53.344Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-17T01:51:57.705Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T01:52:03.157Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T01:52:44.996Z"
   },
   {
    "duration": 84,
    "start_time": "2023-03-17T01:54:21.931Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-17T16:05:09.492Z"
   },
   {
    "duration": 613,
    "start_time": "2023-03-17T16:05:14.390Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T16:05:15.009Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-17T16:05:15.035Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-17T16:05:15.054Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-17T16:05:15.078Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-17T16:05:18.235Z"
   },
   {
    "duration": 954,
    "start_time": "2023-03-17T16:13:20.267Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-17T16:13:26.364Z"
   },
   {
    "duration": 25,
    "start_time": "2023-03-17T16:13:26.418Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T16:13:26.445Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-17T16:13:26.452Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-17T16:13:26.476Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-17T16:13:26.509Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T16:13:26.529Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-17T16:13:26.544Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-17T16:13:26.563Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T16:13:26.634Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-17T16:13:26.642Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-17T16:13:26.654Z"
   },
   {
    "duration": 87,
    "start_time": "2023-03-17T16:13:26.668Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-17T16:13:26.757Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-17T16:13:26.768Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-17T16:13:28.395Z"
   },
   {
    "duration": 216,
    "start_time": "2023-03-17T16:15:35.923Z"
   },
   {
    "duration": 72,
    "start_time": "2023-03-17T16:19:48.134Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T16:20:01.340Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T16:20:12.818Z"
   },
   {
    "duration": 34,
    "start_time": "2023-03-17T16:20:14.275Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-17T16:24:56.700Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-17T16:25:14.252Z"
   },
   {
    "duration": 15259,
    "start_time": "2023-03-17T16:25:16.497Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T16:25:54.268Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T16:26:01.347Z"
   },
   {
    "duration": 7444,
    "start_time": "2023-03-17T16:27:47.794Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T16:27:57.727Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-17T16:32:24.612Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T16:32:24.654Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-17T16:32:24.669Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-17T16:32:24.683Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-17T16:32:24.703Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-17T16:32:24.722Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-17T16:32:24.738Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-17T16:32:24.749Z"
   },
   {
    "duration": 50,
    "start_time": "2023-03-17T16:32:24.766Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T16:32:24.818Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T16:32:24.826Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T16:32:24.841Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-17T16:32:24.849Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-17T16:32:24.858Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-17T16:32:24.867Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-17T16:32:24.917Z"
   },
   {
    "duration": 68,
    "start_time": "2023-03-17T16:32:24.949Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T16:32:25.099Z"
   },
   {
    "duration": 110,
    "start_time": "2023-03-17T16:32:25.104Z"
   },
   {
    "duration": 206,
    "start_time": "2023-03-17T16:32:25.216Z"
   },
   {
    "duration": 7089,
    "start_time": "2023-03-17T16:32:25.424Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T16:32:32.515Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-17T16:32:32.520Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T16:32:32.552Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-17T16:32:32.560Z"
   },
   {
    "duration": 16599,
    "start_time": "2023-03-17T16:35:19.954Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T16:36:38.627Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T16:36:52.308Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-17T16:37:52.972Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-17T16:38:55.650Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-17T16:40:17.319Z"
   },
   {
    "duration": 71,
    "start_time": "2023-03-17T16:40:19.351Z"
   },
   {
    "duration": 138,
    "start_time": "2023-03-17T16:40:29.056Z"
   },
   {
    "duration": 111,
    "start_time": "2023-03-17T16:41:15.805Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-17T16:42:28.151Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-17T16:43:13.318Z"
   },
   {
    "duration": 29,
    "start_time": "2023-03-17T16:43:15.542Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-17T17:02:04.099Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-17T17:02:04.156Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-17T17:02:04.174Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-17T17:02:04.188Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-17T17:02:04.228Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-17T17:02:04.276Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T17:02:04.329Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-17T17:02:04.355Z"
   },
   {
    "duration": 38,
    "start_time": "2023-03-17T17:02:04.381Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-17T17:02:04.421Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-17T17:02:04.427Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-17T17:02:04.439Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-17T17:02:04.459Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-17T17:02:04.474Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-17T17:02:04.491Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-17T17:02:04.533Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-17T17:02:04.559Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-17T17:02:04.620Z"
   },
   {
    "duration": 131,
    "start_time": "2023-03-17T17:02:04.701Z"
   },
   {
    "duration": 198,
    "start_time": "2023-03-17T17:02:04.835Z"
   },
   {
    "duration": 6872,
    "start_time": "2023-03-17T17:02:05.034Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T17:02:11.912Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-17T17:02:11.918Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-17T17:02:11.942Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-17T17:02:11.949Z"
   },
   {
    "duration": 21108,
    "start_time": "2023-03-17T17:02:11.959Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-17T17:02:33.069Z"
   },
   {
    "duration": 15283,
    "start_time": "2023-03-17T17:02:33.075Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-17T17:02:48.360Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-17T17:02:48.365Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-17T17:02:48.412Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-17T17:02:48.425Z"
   },
   {
    "duration": 207,
    "start_time": "2023-03-17T17:02:48.507Z"
   },
   {
    "duration": 113,
    "start_time": "2023-03-17T17:02:48.720Z"
   },
   {
    "duration": 82,
    "start_time": "2023-03-17T17:02:48.834Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nbTranslate": {
   "displayLangs": [],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "ru",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
